{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gP-v0E_S-mQP"
   },
   "source": [
    "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
    "\n",
    "# Handwritten Text Recognition using TensorFlow 2.0\n",
    "\n",
    "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMty1YwuWHpN"
   },
   "source": [
    "## 1 Localhost Environment\n",
    "\n",
    "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39blvPTPQJpt"
   },
   "source": [
    "### 1.1 Datasets\n",
    "\n",
    "The datasets that you can use:\n",
    "\n",
    "a. [Bentham](http://transcriptorium.eu/datasets/bentham-collection/)\n",
    "\n",
    "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
    "\n",
    "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
    "\n",
    "d. [Saint Gall](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/saint-gall-database)\n",
    "\n",
    "e. [Washington](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/washington-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVBGMLifWQwl"
   },
   "source": [
    "### 1.2 Raw folder\n",
    "\n",
    "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
    "\n",
    "> ```python -m venv .venv && source .venv/bin/activate```\n",
    "\n",
    "> ```pip install -r requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyLRbAwsWSYA"
   },
   "source": [
    "### 1.3 HDF5 files\n",
    "\n",
    "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
    "\n",
    "> ```python main.py --source=<DATASET_NAME> --transform```\n",
    "\n",
    "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── bentham.hdf5\n",
    "│   ├── iam.hdf5\n",
    "│   ├── rimes.hdf5\n",
    "│   ├── saintgall.hdf5\n",
    "│   └── washington.hdf5\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Then upload the **data** and **src** folders in the same directory in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jydsAcWgWVth"
   },
   "source": [
    "## 2 Google Drive Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk3e7YJiXzSl"
   },
   "source": [
    "### 2.1 TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7twXyNGXtbJ"
   },
   "source": [
    "Make sure the jupyter notebook is using GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHw4tODULT1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  5 20:06:25 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    38W / 250W |    579MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     30198      C   /usr/bin/python3                             569MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJECz8H8XVCY"
   },
   "source": [
    "Now, we'll install TensorFlow 2.0 with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMg-B5PH9h3r"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-gpu==2.1.0-rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5ukHtpZiz0g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.0.0\n",
      "\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('Tensorflow Version: {}\\n'.format(tf.version.VERSION))\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyMv5wyDXxqc"
   },
   "source": [
    "### 2.2 Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5gj6qwoX9W3"
   },
   "source": [
    "Mount your Google Drive partition.\n",
    "\n",
    "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACQn1iBF9k9O"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"./gdrive\", force_remount=True)\n",
    "\n",
    "# %cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n",
    "# !ls -l\n",
    "import h5py\n",
    "# filename = '../data/bentham.hdf5'\n",
    "\n",
    "# with h5py.File(filename, 'r') as f:\n",
    "#     # List all groups\n",
    "#     print(\"Keys: %s\" % f.keys())\n",
    "#     a_group_key = list(f.keys())[0]\n",
    "\n",
    "#     # Get the data\n",
    "#     data = list(f[a_group_key])\n",
    "    \n",
    "#     print(f['train']['dt'][5])\n",
    "#     print(f['train']['gt'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwogUA8RZAyp"
   },
   "source": [
    "After mount, you can see the list os files in the project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fj7fSngY1IX"
   },
   "source": [
    "## 3 Set Python Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6Q4cOlWhNl3"
   },
   "source": [
    "### 3.1 Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvqL2Eq5ZUc7"
   },
   "source": [
    "First, let's define our environment variables.\n",
    "\n",
    "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
    "\n",
    "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
    "\n",
    "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
    "\n",
    "* **epochs**: number of epochs\n",
    "\n",
    "* **batch_size**: number size of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Qpr3drnGMWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ../data/hw-text.hdf5\n",
      "output ../output/hw-text/flor\n",
      "target ../output/flor/checkpoint_weights.hdf5\n",
      "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# define parameters\n",
    "source = \"hw-text\"\n",
    "arch = \"flor\"\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "# define paths\n",
    "source_path = os.path.join(\"..\", \"data\", \"{}.hdf5\".format(source))\n",
    "output_path = os.path.join(\"..\", \"output\", source, arch)\n",
    "target_path = os.path.join(\"..\", \"output\", arch, \"checkpoint_weights.hdf5\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# define input size, number max of chars per line and list of valid chars\n",
    "input_size = (1024, 128, 1)\n",
    "max_text_length = 128\n",
    "charset_base = string.printable[:95]\n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"output\", output_path)\n",
    "print(\"target\", target_path)\n",
    "print(\"charset:\", charset_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFextshOhTKr"
   },
   "source": [
    "### 3.2 DataGenerator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfZ1mfvsanu1"
   },
   "source": [
    "The second class is **DataGenerator()**, responsible for:\n",
    "\n",
    "* Load the dataset partitions (train, valid, test);\n",
    "\n",
    "* Manager batchs for train/validation/test process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k9vpNzMIAi2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 20962\n",
      "Validation images: 5978\n",
      "Test images: 3048\n"
     ]
    }
   ],
   "source": [
    "from data.generator import DataGenerator\n",
    "\n",
    "dtgen = DataGenerator(source=source_path,\n",
    "                      batch_size=batch_size,\n",
    "                      charset=charset_base,\n",
    "                      max_text_length=max_text_length)\n",
    "\n",
    "print(\"Train images: {}\".format(dtgen.size['train']))\n",
    "print(\"Validation images: {}\".format(dtgen.size['valid']))\n",
    "print(\"Test images: {}\".format(dtgen.size['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OdgNLK0hYAA"
   },
   "source": [
    "### 3.3 HTRModel Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHktk8AFcnKy"
   },
   "source": [
    "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
    "\n",
    "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
    "\n",
    "* Save and load model;\n",
    "\n",
    "* Load weights in the models (train/infer);\n",
    "\n",
    "* Make Train/Predict process using *generator*.\n",
    "\n",
    "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nV0GreStISTR"
   },
   "outputs": [],
   "source": [
    "from network.model import HTRModel\n",
    "\n",
    "# create and compile HTRModel\n",
    "# note: `learning_rate=None` will get architecture default value\n",
    "model = HTRModel(architecture=arch, input_size=input_size, vocab_size=dtgen.tokenizer.vocab_size)\n",
    "model.compile(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
    "model.load_checkpoint(target=target_path)\n",
    "\n",
    "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KASq6zqogG6Q"
   },
   "source": [
    "## 4 Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8eBxuoogM-d"
   },
   "source": [
    "To facilitate the visualization of the model's training, you can instantiate the Tensorboard. \n",
    "\n",
    "**Note**: All data is saved in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPx4hRHuJGAd"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --reload_interval=300 --logdir={output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1fnz0Eugqru"
   },
   "source": [
    "## 5 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1mLOcqYgsO-"
   },
   "source": [
    "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P6MSoxCISlD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 656 steps, validate for 187 steps\n",
      "655/656 [============================>.] - ETA: 0s - loss: 0.7720\n",
      "Epoch 00001: val_loss improved from inf to 1.31339, saving model to ../output/flor/checkpoint_weights.hdf5\n",
      "656/656 [==============================] - 228s 347ms/step - loss: 0.7709 - val_loss: 1.3134\n",
      "Total train images:      20962\n",
      "Total validation images: 5978\n",
      "Batch:                   32\n",
      "\n",
      "Total time:              0:03:48.105753\n",
      "Time per epoch:          0:03:48.105753\n",
      "Time per item:           0:00:00.008467\n",
      "\n",
      "Total epochs:            1\n",
      "Best epoch               1\n",
      "\n",
      "Training loss:           0.771896550430959\n",
      "Validation loss:         1.3133854809650445\n"
     ]
    }
   ],
   "source": [
    "# to calculate total and average time per epoch\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=dtgen.next_train_batch(),\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=dtgen.steps['train'],\n",
    "              validation_data=dtgen.next_valid_batch(),\n",
    "              validation_steps=dtgen.steps['valid'],\n",
    "              callbacks=callbacks,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "             use_multiprocessing=True)\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    \"Total train images:      {}\".format(dtgen.size['train']),\n",
    "    \"Total validation images: {}\".format(dtgen.size['valid']),\n",
    "    \"Batch:                   {}\\n\".format(dtgen.batch_size),\n",
    "    \"Total time:              {}\".format(total_time),\n",
    "    \"Time per epoch:          {}\".format(time_epoch),\n",
    "    \"Time per item:           {}\\n\".format(time_epoch / total_item),\n",
    "    \"Total epochs:            {}\".format(len(loss)),\n",
    "    \"Best epoch               {}\\n\".format(min_val_loss_i + 1),\n",
    "    \"Training loss:           {}\".format(loss[min_val_loss_i]),\n",
    "    \"Validation loss:         {}\".format(min_val_loss)\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13g7tDjWgtXV"
   },
   "source": [
    "## 6 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddO26OT-g_QK"
   },
   "source": [
    "The predict process is similar to the *predict* of the Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9iHL6tmaL_j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predict\n",
      "96/96 [==============================] - 9s 93ms/step\n",
      "CTC Decode\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py:5783: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "96/96 [==============================] - 105s 1s/step\n",
      "==================================================================================================== \n",
      "\n",
      "71 Sylvia run\n",
      "71 Sylvia ri \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Studio 04o Stevenson cliffs\n",
      "Studio 04o Stevenson clifs \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Studio 66n Haynes ranch\n",
      "Studio 6n Haynes ranch \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Flat 2 Thomas locks\n",
      "Flat 2 Thomas locks \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Dr . Emma Steele\n",
      "Dr . Ema Stele \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Miss Nicola Burrows Tuckerport\n",
      "Mis Nicola Burows Tuckerport \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Studio 49L Bruce hollow\n",
      "Studio 49 Bruce holow \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Dr . Damien Mitchell\n",
      "Dr . Davien - Mitchel \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Miah - Foster\n",
      "Miah - Foster \n",
      "\n",
      "==================================================================================================== \n",
      "\n",
      "Howard Morgan Parkerchester\n",
      "Howard Morgan Parkerchester \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import preproc as pp\n",
    "from cv2 import imshow as cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# predict() function will return the predicts with the probabilities\n",
    "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
    "                            steps=dtgen.steps['test'],\n",
    "                            ctc_decode=True,\n",
    "                            verbose=1)\n",
    "\n",
    "# decode to string\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "# mount predict corpus file\n",
    "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
    "    for pd, gt in zip(predicts, dtgen.dataset['test']['gt']):\n",
    "        lg.write(\"TE_L {}\\nTE_P {}\\n\".format(gt, pd))\n",
    "   \n",
    "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
    "    print(\"=\" * 100, \"\\n\")\n",
    "    plt.imshow(pp.adjust_to_see(item))\n",
    "    print(dtgen.dataset['test']['gt'][i])\n",
    "    print(predicts[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JcAs3Q3WNJ-"
   },
   "source": [
    "## 7 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LuZBRepWbom"
   },
   "source": [
    "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
    "\n",
    "* predicts\n",
    "* ground_truth\n",
    "* norm_accentuation (calculation with/without accentuation)\n",
    "* norm_punctuation (calculation with/without punctuation marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gCwEYdKWOPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images:    3048\n",
      "Total time:           0:01:54.852684\n",
      "Time per item:        0:00:00.037681\n",
      "\n",
      "Metrics:\n",
      "Character Error Rate: 0.047492691046496234\n",
      "Word Error Rate:      0.21719355393075868\n",
      "Sequence Error Rate:  0.5442913385826772\n"
     ]
    }
   ],
   "source": [
    "from data import evaluation\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts=predicts,\n",
    "                                  ground_truth=dtgen.dataset['test']['gt'],\n",
    "                                  norm_accentuation=False,\n",
    "                                  norm_punctuation=False)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    \"Total test images:    {}\".format(dtgen.size['test']),\n",
    "    \"Total time:           {}\".format(total_time),\n",
    "    \"Time per item:        {}\\n\".format(total_time / dtgen.size['test']),\n",
    "    \"Metrics:\",\n",
    "    \"Character Error Rate: {}\".format(evaluate[0]),\n",
    "    \"Word Error Rate:      {}\".format(evaluate[1]),\n",
    "    \"Sequence Error Rate:  {}\".format(evaluate[2])\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
    "    lg.write(e_corpus)\n",
    "    print(e_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import preproc as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = '../0_BusinessName_196_331.png'\n",
    "pp_img = pp.normalization(pp.preproc(test_img, input_size ).reshape(1024,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efdac589588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(pp.adjust_to_see(pp.preproc(test_img, input_size )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predict\n",
      "1/1 [==============================] - 2s 2s/sample\n",
      "CTC Decode\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Reynolds - Reid']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts, _= model.predict(x=pp_img.reshape(1,1024,128,1),\n",
    "                            steps=1,\n",
    "                            ctc_decode=True,\n",
    "                            verbose=1)\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../htr_saved_model_v1/htr_saved_model_v1/assets\n"
     ]
    }
   ],
   "source": [
    "# saving model for serving\n",
    "model.model.save('../htr_saved_model_v1/htr_saved_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "oMty1YwuWHpN"
   ],
   "name": "tutorial.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
